{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UnYEeocQ97-Z6IXD-b5PRtdwyx9AFZ1g",
      "authorship_tag": "ABX9TyNs77GDpPnMK8MUp+vBq0x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamThapa243/Information-Retrieval/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRE PROCESSING**"
      ],
      "metadata": {
        "id": "uf3b75i_GyaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LNDXFUJk5Wdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUze42NYDnpY",
        "outputId": "cb055291-6a7f-4bbb-d6d6-574899c13b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# importing dataset from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check Point: Checking if the files are readable*"
      ],
      "metadata": {
        "id": "XdiZptKUHT06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the dattaset\n",
        "path = \"/content/drive/MyDrive/Dataset/text_files/file1.txt\"\n",
        "with open(path, 'r') as file:\n",
        "  content = file.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYhURooYGOVb",
        "outputId": "b6f5bc6e-6cf5-4333-982c-a8f3f595e6dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function definitions (include preprocessing functions)**"
      ],
      "metadata": {
        "id": "L9rC0MdupFwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from types import new_class\n",
        "def preprocessing(document):\n",
        "  # 1. converting the string into lowercase and removing meta-tags\n",
        "  content = document.lower()\n",
        "  content = metadata_remover(content)\n",
        "\n",
        "  # 2. converting string into tokens\n",
        "  token_array = tokenizer_function(content)\n",
        "\n",
        "  # 3. removing stopwords\n",
        "  token_array = stopwords_remover_funtion(token_array)\n",
        "\n",
        "  # 4. Punctuation remover function\n",
        "  token_array = punctuation_remover_function(token_array)\n",
        "\n",
        "  # 5. converting token array to string,\n",
        "  # so that it can be stored as a string in the text file\n",
        "  preprocessed_tokens = stringfy_token_array(token_array)\n",
        "\n",
        "  # 6. removing extra spaces\n",
        "  preprocessed_tokens = ' '.join(preprocessed_tokens.split())\n",
        "\n",
        "  return preprocessed_tokens\n",
        "# end of functtion\n",
        "\n",
        "\n",
        "# function to convert the string into lower case and no meta data\n",
        "def metadata_remover(content):\n",
        "  tag = False\n",
        "  quote = False\n",
        "  str = \"\"\n",
        "  for ch in content:\n",
        "    if ch == '<' and not quote:\n",
        "      tag = True\n",
        "    elif ch == '>' and not quote:\n",
        "      tag = False\n",
        "    elif (ch == '\"' or ch == \"'\") and tag:\n",
        "      quote = not quote\n",
        "    elif not tag:\n",
        "      str = str + ch\n",
        "\n",
        "  return str\n",
        "# end of function\n",
        "\n",
        "# function to convert string into tokens\n",
        "def tokenizer_function(content):\n",
        "  token_array = content.split()\n",
        "  return token_array\n",
        "# end of function\n",
        "\n",
        "# funtion to remove stopwords from the token array\n",
        "def stopwords_remover_funtion(token_array):\n",
        "  stopwords = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
        "                 \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
        "                 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',\n",
        "                 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is',\n",
        "                 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
        "                 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
        "                 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\n",
        "                 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
        "                 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',\n",
        "                 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n",
        "                 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\",\n",
        "                 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n",
        "                 \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
        "                 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
        "                 \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"}\n",
        "  new_array = []\n",
        "  for token in token_array:\n",
        "    if token in stopwords:\n",
        "      continue\n",
        "    else:\n",
        "      new_array.append(token)\n",
        "  return new_array\n",
        "# end of funtion\n",
        "\n",
        "# funtion to remove punctuation\n",
        "def punctuation_remover_function(token_array):\n",
        "  new_token = []\n",
        "  puntuation = {'.', '?', '!', ',', ';', ':', '\\'', '\\\"', '-', '_', ')', '(', '[', ']', '{', '}', '<', '>', '=', '/', '\\\\', '*', '#' }\n",
        "  for token in token_array:\n",
        "    temp = \"\"\n",
        "    for ch in token:\n",
        "      if  ch in puntuation:\n",
        "        temp += \" \"\n",
        "      else:\n",
        "        temp += ch\n",
        "    new_token.append(temp)\n",
        "  return new_token\n",
        "#end of function\n",
        "\n",
        "# function to convert token array into string\n",
        "def stringfy_token_array(token_array):\n",
        "  token_string = \"\"\n",
        "  token_string = ' '.join(token_array)\n",
        "  return token_string\n",
        "# end of function"
      ],
      "metadata": {
        "id": "Kw3QIKqapFT9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check Point: Checking if the preprocessing stage is working fine*"
      ],
      "metadata": {
        "id": "uLazDVQtyJjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val = \"Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\"\n",
        "print(val)\n",
        "print(preprocessing(val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9oZkAW5MClQ",
        "outputId": "8ec2a37b-e192-4dfa-91e5-9121f11dd40c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "loving vintage springs vintage strat good tension great stability floating bridge want springs way go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the file content and storing in a new directory**"
      ],
      "metadata": {
        "id": "_bi24OpNBHrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/Dataset/text_files\"\n",
        "preprocessed_directory = \"/content/drive/MyDrive/Preprocessed-Dataset\"\n",
        "# Create the preprocessed directory if it doesn't exist\n",
        "os.makedirs(preprocessed_directory, exist_ok= True)\n",
        "\n",
        "# List all files in the directory, excluding subdirectories\n",
        "file_list = os.listdir(directory_path)\n",
        "\n",
        "# iterating through the dataset and preprocessing each file present in the directory\n",
        "for filename in file_list:\n",
        "  file_path = os.path.join(directory_path, filename)\n",
        "  # reading the original content of the dataset\n",
        "  with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "  # preprocessing the original document\n",
        "  preprocessed_content = preprocessing(content)\n",
        "\n",
        "  # writing/ storing the preprocessed_content into the newly created directory\n",
        "  preprocessed_file_path = os.path.join(preprocessed_directory, filename)\n",
        "  with open(preprocessed_file_path, 'w') as preprocessed_file:\n",
        "    preprocessed_file.write(preprocessed_content)\n",
        "#end of for loop"
      ],
      "metadata": {
        "id": "xTQzUeplnIli"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing 5 Original documents before and after preprocessing"
      ],
      "metadata": {
        "id": "gOqoGDkb_jph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_directoory_path = \"/content/drive/MyDrive/Dataset/text_files\"\n",
        "preprocessed_directory_path = \"/content/drive/MyDrive/Preprocessed-Dataset\"\n",
        "\n",
        "preprocessed_file_list = os.listdir(preprocessed_directory_path)\n",
        "origibanal_file_list = os.listdir(original_directoory_path)\n",
        "\n",
        "file_count = 1\n",
        "\n",
        "for filename in preprocessed_file_list:\n",
        "  if file_count > 5:\n",
        "    break\n",
        "\n",
        "  print(file_count, f\" {filename}\")\n",
        "\n",
        "  original_file_path = os.path.join(original_directoory_path, filename)\n",
        "  with open(original_file_path, 'r') as file:\n",
        "    original_content = file.read()\n",
        "\n",
        "  preprocessed_file_path = os.path.join(preprocessed_directory_path, filename)\n",
        "  with open(preprocessed_file_path, 'r') as file:\n",
        "    preprocessed_content = file.read()\n",
        "\n",
        "  print(\"ORIGINAL CONTENT : \\n-\", original_content)\n",
        "  print(\"PREPROCESSED CONTENT : \\n-\" , preprocessed_content)\n",
        "  print(\"-----------\")\n",
        "  file_count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmSr5DD_hxy",
        "outputId": "4ecb03fc-df0b-48a8-ca83-7b75354c02e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  file732.txt\n",
            "ORIGINAL CONTENT : \n",
            "- Tha best! leads\n",
            "PREPROCESSED CONTENT : \n",
            "- tha best leads\n",
            "-----------\n",
            "2  file214.txt\n",
            "ORIGINAL CONTENT : \n",
            "- A lot of the reviews for this are divided. \"Oh, it sounds great,\" and \"sounds like a s***ty gong\" come to mind. I bought it anyways. It is definitely a cheap buy, and still looks like an amazing cymbal. As for sound, it does sound pretty crappy. But it's still a great buy for beginner drummers, or drummer who just like to jam out in their basements/garage. Once you start to get a gig or two, you should consider going with a better cymbal\n",
            "\n",
            "UPDATE: I've had the cymbal for about 1.5 years, and it's cracked to the point where I can't play it anymore. It's MOST likely because of the way I've been hitting it, and NOT because of crappy manufacturing. As I look at my old review I think I was a bit critical. I've grown to love the bright sound of this cymbal, and will probably buy another one\n",
            "PREPROCESSED CONTENT : \n",
            "- lot reviews divided oh sounds great sounds like s ty gong come mind bought anyways definitely cheap buy still looks like amazing cymbal sound sound pretty crappy still great buy beginner drummers drummer like jam basements garage start get gig two consider going better cymbal update i ve cymbal 1 5 years cracked point can t play anymore likely way i ve hitting it crappy manufacturing look old review think bit critical i ve grown love bright sound cymbal probably buy another one\n",
            "-----------\n",
            "3  file605.txt\n",
            "ORIGINAL CONTENT : \n",
            "- My application of this is to plug three guitars in to my pedalboard (see pics).  It is noiseless, and shows no tone-sucking qualities at all.  It runs well off a 9-volt or a Dunlop DC Brick, although that is just for the function of the lights.  It also works with no power at all (but the lights come in handy to know which selection is ON).\n",
            "PREPROCESSED CONTENT : \n",
            "- application plug three guitars pedalboard see pics noiseless shows tone sucking qualities all runs well 9 volt dunlop dc brick although function lights also works power but lights come handy know selection on\n",
            "-----------\n",
            "4  file90.txt\n",
            "ORIGINAL CONTENT : \n",
            "- A solid strap that I used on my Strat.  Very nice.  It's not flashy, which fits my style well.  Works well, solidly made.  No worries that the guitar is going to come off while playing.  I've taken some shots of the Poly Locks, check out the mechanism.  It's pretty nice.  Definitely will do what you want and last a good long while.\n",
            "PREPROCESSED CONTENT : \n",
            "- solid strap used strat nice flashy fits style well works well solidly made worries guitar going come playing i ve taken shots poly locks check mechanism pretty nice definitely want last good long while\n",
            "-----------\n",
            "5  file186.txt\n",
            "ORIGINAL CONTENT : \n",
            "- I bought two kits for a total of six guitar stand/holders. I don't know why they're described as \"Acoustic\" holders, I'm them using them to hold a heavy Fender Precision bass, and other standard electric guitars. They're easy to install, but as others have written, do not use the fasteners that come in the kit. They are cheaply made and are unsafe. I simply stopped by Walmart and picked up a couple packs of self-drilling drywall anchors (pictured). They're inexpensive fasteners and helped make the installation a breeze. I was able to install all six guitar stands in about 30 minutes.\n",
            "I highly recommend this product -  as long as you use upgraded fasteners,\n",
            "PREPROCESSED CONTENT : \n",
            "- bought two kits total six guitar stand holders know they re described acoustic holders i m using hold heavy fender precision bass standard electric guitars they re easy install others written use fasteners come kit cheaply made unsafe simply stopped walmart picked couple packs self drilling drywall anchors pictured they re inexpensive fasteners helped make installation breeze able install six guitar stands 30 minutes highly recommend product long use upgraded fasteners\n",
            "-----------\n"
          ]
        }
      ]
    }
  ]
}