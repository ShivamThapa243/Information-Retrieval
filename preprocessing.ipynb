{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UnYEeocQ97-Z6IXD-b5PRtdwyx9AFZ1g",
      "authorship_tag": "ABX9TyPnrSXAcYHgI1nJnSGwbf6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamThapa243/Information-Retrieval/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRE PROCESSING**"
      ],
      "metadata": {
        "id": "uf3b75i_GyaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LNDXFUJk5Wdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUze42NYDnpY",
        "outputId": "cb055291-6a7f-4bbb-d6d6-574899c13b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# importing dataset from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check Point: Checking if the files are readable*"
      ],
      "metadata": {
        "id": "XdiZptKUHT06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the dattaset\n",
        "path = \"/content/drive/MyDrive/Dataset/text_files/file1.txt\"\n",
        "with open(path, 'r') as file:\n",
        "  content = file.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYhURooYGOVb",
        "outputId": "b6f5bc6e-6cf5-4333-982c-a8f3f595e6dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function definitions (include preprocessing functions)**"
      ],
      "metadata": {
        "id": "L9rC0MdupFwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from types import new_class\n",
        "def preprocessing(document):\n",
        "  # 1. converting the string into lowercase and removing meta-tags\n",
        "  content = document.lower()\n",
        "  content = metadata_remover(content)\n",
        "\n",
        "  # 2. converting string into tokens\n",
        "  token_array = tokenizer_function(content)\n",
        "\n",
        "  # 3. removing stopwords\n",
        "  token_array = stopwords_remover_funtion(token_array)\n",
        "\n",
        "  # 4. Punctuation remover function\n",
        "  token_array = punctuation_remover_function(token_array)\n",
        "\n",
        "  # 5. converting token array to string,\n",
        "  # so that it can be stored as a string in the text file\n",
        "  preprocessed_tokens = stringfy_token_array(token_array)\n",
        "\n",
        "  # 6. removing extra spaces\n",
        "  preprocessed_tokens = ' '.join(preprocessed_tokens.split())\n",
        "\n",
        "  return preprocessed_tokens\n",
        "# end of functtion\n",
        "\n",
        "\n",
        "# function to convert the string into lower case and no meta data\n",
        "def metadata_remover(content):\n",
        "  tag = False\n",
        "  quote = False\n",
        "  str = \"\"\n",
        "  for ch in content:\n",
        "    if ch == '<' and not quote:\n",
        "      tag = True\n",
        "    elif ch == '>' and not quote:\n",
        "      tag = False\n",
        "    elif (ch == '\"' or ch == \"'\") and tag:\n",
        "      quote = not quote\n",
        "    elif not tag:\n",
        "      str = str + ch\n",
        "\n",
        "  return str\n",
        "# end of function\n",
        "\n",
        "# function to convert string into tokens\n",
        "def tokenizer_function(content):\n",
        "  token_array = content.split()\n",
        "  return token_array\n",
        "# end of function\n",
        "\n",
        "# funtion to remove stopwords from the token array\n",
        "def stopwords_remover_funtion(token_array):\n",
        "  stopwords = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
        "                 \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
        "                 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',\n",
        "                 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is',\n",
        "                 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
        "                 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
        "                 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\n",
        "                 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
        "                 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',\n",
        "                 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n",
        "                 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\",\n",
        "                 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n",
        "                 \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
        "                 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
        "                 \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"}\n",
        "  new_array = []\n",
        "  for token in token_array:\n",
        "    if token in stopwords:\n",
        "      continue\n",
        "    else:\n",
        "      new_array.append(token)\n",
        "  return new_array\n",
        "# end of funtion\n",
        "\n",
        "# funtion to remove punctuation\n",
        "def punctuation_remover_function(token_array):\n",
        "  new_token = []\n",
        "  puntuation = {'.', '?', '!', ',', ';', ':', '\\'', '\\\"', '-', '_', ')', '(', '[', ']', '{', '}', '<', '>', '=', '/', '\\\\', '*', '#' }\n",
        "  for token in token_array:\n",
        "    temp = \"\"\n",
        "    for ch in token:\n",
        "      if  ch in puntuation:\n",
        "        temp += \" \"\n",
        "      else:\n",
        "        temp += ch\n",
        "    new_token.append(temp)\n",
        "  return new_token\n",
        "#end of function\n",
        "\n",
        "# function to convert token array into string\n",
        "def stringfy_token_array(token_array):\n",
        "  token_string = \"\"\n",
        "  token_string = ' '.join(token_array)\n",
        "  return token_string\n",
        "# end of function"
      ],
      "metadata": {
        "id": "Kw3QIKqapFT9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check Point: Checking if the preprocessing stage is working fine*"
      ],
      "metadata": {
        "id": "uLazDVQtyJjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val = \"Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\"\n",
        "print(val)\n",
        "print(preprocessing(val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9oZkAW5MClQ",
        "outputId": "8ec2a37b-e192-4dfa-91e5-9121f11dd40c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "loving vintage springs vintage strat good tension great stability floating bridge want springs way go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the file content and storing in a new directory**"
      ],
      "metadata": {
        "id": "_bi24OpNBHrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/Dataset/text_files\"\n",
        "preprocessed_directory = \"/content/drive/MyDrive/Preprocessed-Dataset\"\n",
        "# Create the preprocessed directory if it doesn't exist\n",
        "os.makedirs(preprocessed_directory, exist_ok= True)\n",
        "\n",
        "# List all files in the directory, excluding subdirectories\n",
        "file_list = os.listdir(directory_path)\n",
        "\n",
        "# iterating through the dataset and preprocessing each file present in the directory\n",
        "for filename in file_list:\n",
        "  file_path = os.path.join(directory_path, filename)\n",
        "  # reading the original content of the dataset\n",
        "  with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "  # preprocessing the original document\n",
        "  preprocessed_content = preprocessing(content)\n",
        "\n",
        "  # writing/ storing the preprocessed_content into the newly created directory\n",
        "  preprocessed_file_path = os.path.join(preprocessed_directory, filename)\n",
        "  with open(preprocessed_file_path, 'w') as preprocessed_file:\n",
        "    preprocessed_file.write(preprocessed_content)\n",
        "#end of for loop"
      ],
      "metadata": {
        "id": "xTQzUeplnIli"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing 5 Original documents before and after preprocessing"
      ],
      "metadata": {
        "id": "gOqoGDkb_jph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_directory_path = \"/content/drive/MyDrive/Preprocessed-Dataset\"\n",
        "preprocessed_file_list = os.listdir(preprocessed_directory_path)\n",
        "\n",
        "file_count = 1\n",
        "\n",
        "for filename in preprocessed_file_list:\n",
        "  if file_count > 5:\n",
        "    break\n",
        "\n",
        "  preprocessed_file_path = os.path.join(preprocessed_directory_path, filename)\n",
        "  with open(preprocessed_file_path, 'r') as file:\n",
        "    preprocessed_content = file.read()\n",
        "\n",
        "  print(file_count, f\" {filename}\")\n",
        "  print(preprocessed_content, \"\\n\")\n",
        "  file_count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmSr5DD_hxy",
        "outputId": "6db7cca6-d7c4-498b-da8c-8b236c143953"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  file732.txt\n",
            "tha best leads \n",
            "\n",
            "2  file214.txt\n",
            "lot reviews divided oh sounds great sounds like s ty gong come mind bought anyways definitely cheap buy still looks like amazing cymbal sound sound pretty crappy still great buy beginner drummers drummer like jam basements garage start get gig two consider going better cymbal update i ve cymbal 1 5 years cracked point can t play anymore likely way i ve hitting it crappy manufacturing look old review think bit critical i ve grown love bright sound cymbal probably buy another one \n",
            "\n",
            "3  file605.txt\n",
            "application plug three guitars pedalboard see pics noiseless shows tone sucking qualities all runs well 9 volt dunlop dc brick although function lights also works power but lights come handy know selection on \n",
            "\n",
            "4  file90.txt\n",
            "solid strap used strat nice flashy fits style well works well solidly made worries guitar going come playing i ve taken shots poly locks check mechanism pretty nice definitely want last good long while \n",
            "\n",
            "5  file186.txt\n",
            "bought two kits total six guitar stand holders know they re described acoustic holders i m using hold heavy fender precision bass standard electric guitars they re easy install others written use fasteners come kit cheaply made unsafe simply stopped walmart picked couple packs self drilling drywall anchors pictured they re inexpensive fasteners helped make installation breeze able install six guitar stands 30 minutes highly recommend product long use upgraded fasteners \n",
            "\n"
          ]
        }
      ]
    }
  ]
}