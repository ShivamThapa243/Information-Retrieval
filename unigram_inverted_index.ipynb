{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz8HrE6gl9lOICzuNoLLRj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamThapa243/Information-Retrieval/blob/main/unigram_inverted_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNIGRAM INVERTED INDEX\n",
        "\n"
      ],
      "metadata": {
        "id": "jyfiLkRMO8B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1. Building Unigram Inverted Index**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZ1G8EOl-_QW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7eGwA0lqOwVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec97fa6-5cd9-4e61-e4d1-faa50ae8e343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# importing files from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to build an unigram inverted index\n",
        "\n",
        "Structure of inverted index:\n",
        "*   word1: {counts: x, documents: [doc1, dox2, doc3...]}\n",
        "*   word2: {counts: y, documents: [doc3, doc4, doc5...]}\n",
        "*   ...\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "j7t4dLlkaMZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def unigram_inverted_index_builder(dataset_directory):\n",
        "  unigram_inverted_index = {}\n",
        "  list_file = os.listdir(dataset_directory)\n",
        "\n",
        "  # Iterating through each file present in the directory\n",
        "  for filename in list_file:\n",
        "    if filename.endswith(\".txt\"):\n",
        "      # Reading the content of the file\n",
        "      file_path = os.path.join(dataset_directory, filename)\n",
        "      with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "      # tokenizing the documnet to get unique tokens\n",
        "      content_list = content.split()\n",
        "      unique_content = set(content_list)\n",
        "\n",
        "      # Updating the unigram inverted index\n",
        "      for token in unique_content:\n",
        "        # if the token is already in the inverted_index\n",
        "        if token in unigram_inverted_index:\n",
        "          unigram_inverted_index[token]['count'] += 1\n",
        "          if filename not in unigram_inverted_index[token]['documents']:\n",
        "            unigram_inverted_index[token]['documents'].append(filename)\n",
        "        else:\n",
        "          unigram_inverted_index[token] = {'count' : 1, 'documents': [filename]}\n",
        "  return unigram_inverted_index\n"
      ],
      "metadata": {
        "id": "LduAmbNE6wFK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoking the unigram_inverted_index_builder function to build the inverted index"
      ],
      "metadata": {
        "id": "LmVXAr25nggM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# location of preprocessed data set which is stored in the google drive\n",
        "dataset_directory = \"/content/drive/MyDrive/Information Retrieval/preprocessed_data\"\n",
        "\n",
        "# calling the builder function by passing the data set location\n",
        "unigram_inverted_index = unigram_inverted_index_builder(dataset_directory)\n",
        "\n",
        "# storing the newely generated unigram inverted index into a new text file\n",
        "directory_name = \"/content/drive/MyDrive/Information Retrieval\"\n",
        "text_file_name = \"unigram_inverted_index_dataset.txt\"\n",
        "text_file = os.path.join(directory_name, text_file_name)\n",
        "\n",
        "with open(text_file, 'w') as file:\n",
        "  for term, info in unigram_inverted_index.items():\n",
        "    file.write(f\"{term}: {info}\\n\")\n",
        "\n",
        "print(\"Unigram inverted index created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUzZjL0vY2Ar",
        "outputId": "22f1985c-8359-4ffc-e0f4-ae222faf8ff0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram inverted index created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting the inverted index"
      ],
      "metadata": {
        "id": "vmy-QBX0A_vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting the earlier generated unigram inverted index\n",
        "sorted_items = sorted(unigram_inverted_index.items(), key = lambda x : x[0])\n",
        "sorted_inverted_index = dict(sorted_items)\n",
        "\n",
        "# storing the sorted inverted index into a new text file\n",
        "sorted_text_file_name = \"sorted_unigram_inverted_index_dataset.txt\"\n",
        "sorted_text_file = os.path.join(directory_name, sorted_text_file_name)\n",
        "\n",
        "with open(sorted_text_file, 'w') as file:\n",
        "  for term, info in sorted_inverted_index.items():\n",
        "    file.write(f\"{term} : {info}\\n\")\n",
        "\n",
        "print(\"Sorted unigram inverted index created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL35zl0g_6Ho",
        "outputId": "b6f05636-1112-445b-b1b2-5d21ad73e91a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted unigram inverted index created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Pickling the Unigram Inverted Index**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8sBWBqDO_Q5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pkl_file_name = \"sorted_unigram_inverted_index.pkl\"\n",
        "pkl_file_path = os.path.join(directory_name, pkl_file_name)\n",
        "\n",
        "with open(pkl_file_path, 'wb') as file:\n",
        "  pickle.dump(sorted_inverted_index, file)\n",
        "\n",
        "print(\"Sorted unigram inverted index pickled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQXVUG-FFtb",
        "outputId": "a29e651c-2d5f-4991-edc1-72627aa44818"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted unigram inverted index pickled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Providing support for the query operations:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   T1 **AND** T2\n",
        "2.   T1 **OR** T2\n",
        "3.   T1 **AND NOT** T2\n",
        "4.   T1 **OR NOT** T2\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3bXVqClHxTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to preprocess the query and return a preprocessed result"
      ],
      "metadata": {
        "id": "p529pAb3LW8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocessing(query):\n",
        "  # lower case the query\n",
        "  query = query.lower()\n",
        "\n",
        "  # tokenizing\n",
        "  tokens = word_tokenize(query)\n",
        "\n",
        "  # punctuation removal\n",
        "  tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "  # stopwords removal\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxL4tY_wLLnn",
        "outputId": "f33684b8-4ab5-4d20-ebfb-f7ed22a5838a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the pickled file\n",
        "with open(pkl_file_path, 'rb') as file:\n",
        "  inverted_index = pickle.load(file)\n",
        "\n",
        "# input query\n",
        "print(\"Enter input sequence: \")\n",
        "query = input()\n",
        "\n",
        "# input operations\n",
        "print(\"Enter operations (AND, OR, AND NOT, OR NOT) seperated by comams:\")\n",
        "operations = input()\n",
        "\n",
        "# passing the query for preprocessing\n",
        "preprocessed_query = preprocessing(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOkleXUMIcAE",
        "outputId": "e17eba76-c178-49ff-9a0f-14ea84438e47"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter input sequence: \n",
            "Hello, WORlD!\n",
            "Enter operations (AND, OR, AND NOT, OR NOT) seperated by comams:\n",
            "and\n",
            "['hello', 'world']\n"
          ]
        }
      ]
    }
  ]
}